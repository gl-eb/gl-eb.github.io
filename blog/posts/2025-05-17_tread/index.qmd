---
title: "Introducing tread"
description: |
  An R package to extract data from Excel files generated by Tecan Infinite 200 Pro plate readers
date: "2025-05-17"
image: sticker_tread.png
image-alt: |
  A hex sticker with a white background and a dark blue border. The package name tread is found at the top with a graphic depicting a Tecan plate reader below it.
categories: [R, package development, science, PhD]
bibliography: references.yaml
---

This post is marks two special occasions.
This is the first post I'm publishing on my personal website and the topic of the post is my first R package â€” [tread](https://github.com/gl-eb/tread).
While tread has been out in the wild for a while now, this post sat around as an unfinished draft for far too long.
The main goal of it is to document the motivation behind tread, how it progressed from a function within a script to a fully fledged R package, and how I use it in my research.

## Background

I am currently doing my PhD in the [evolutionary microbiology group](https://evomicrobio.ethz.ch/) at ETH Zurich.
As an evolutionary biologist I am often interested in how my bacteria are doing under a particular set of conditions, i.e. what their fitness is.
One easy way to assay fitness of bacteria is to measure the optical density (OD) of a culture and using it as a proxy for growth.
For example, one might grow bacteria at two different temperatures under otherwise equal conditions for a certain duration and then measure their density.
This can be done in a high throughput manner by using a plate reader, which allows measuring multiple samples in a microwell plate.

The particular model of plate reader we use in our group is the Infinite Pro 200, made by the Swiss company Tecan.
The device is connected to a Windows machine and is controlled using the i-control software.
The generated data is written into an Excel spreadsheet.
While Excel spreadsheets are a great way to store data in a human-readable manner, they can pose challenges when one wants to analyse the data in a different environment (e.g. in R or Python).

I needed to regularly measure the fitness of a number of bacterial populations that were part of an evolution experiment.
Since I did not want to manually transfer the OD data from Excel into R (e.g. through an intermediary csv file), I wrote a function that would first read the contents of the sheet and then extract the data.

Over time I needed this function in multiple R projects, so I spun it out into a package and so `tread` was born.

## Parsing Tecan Output

![The header in Tecan's Excel spreadsheets is rather extensive. While I am in favour of metadata, the header also complicates data extraction](tecan_excel_header.png){#fig-tecan-header}

At its core the main function, [`tread::tparse()`](https://www.gl-eb.me/tread/reference/tparse.html), is fairly simple:

1. [`readxl::read_excel()`](https://readxl.tidyverse.org/reference/read_excel.html) is used to load the user-specified sheet from an `.xlsx` file
2. The contents of the sheet are then parsed to detect the type of data.
   This is necessary because each sheet begins with a metadata block (@fig-tecan-header) and the data is shaped differently depending on whether you measure a single or multiple timepoints and how many measurements per well you take
3. The data is then wrangled into [tidy format](https://vita.had.co.nz/papers/tidy-data.html) and returned to the user [@wickhamTidyData2014]

My main use case for `tparse()` is comes from an evolution experiment I am currently running.
The bacterial populations inhabit wells of multiple 48-deep well plates (@fig-plate).
The populations are also separated by buffer wells containing only growth medium.

![The schematic of a 48-well plate as used in my evolution experiment. Blue wells that contain bacterial populations are arranged in a checkerboard pattern with yellow buffer wells containing only growth medium.](well_plate.png){#fig-plate width=80%}

At the end of every cycle I transfer a small volume from all wells of all 48-well plates into a single 96-well plate and measure the OD at a wavelength of 600 nm.
I then run my analysis script which imports optical density data of all experimental cycles and performs a number of operations on the resulting data set:

- The OD values of the buffer wells are checked for outliers. These might indicate an contamination. While most of the time they are easy to spot by eye, I have missed some in the past that the outlier detection flagged
- The OD of the evolving populations is put on a scatter plot. I look at it to see any suspiciously high or low values
- The time series of OD values for each population is plotted so any longer-term trends can be seen


## Segmented Growth Curves

Another use case came up a few cycles into the evolution experiment.
I use growth curves to periodically assess the growth dynamics of the evolving populations.
Since our bacterium grows slower than e.g. *E. coli*, and the evolution experiment is performed in nutrient-limited growth medium, growth curves have to be run for at least 48 hours.
While a growth curve is run, other lab members cannot use the plate reader.
The only solution is to stop and restart the growth curve.
However, this will result in the data being saved into multiple sheets of the same `.xlsx` file.

When stitching together multiple segments of a growth curve, one has to calculate the time offset between them.
This as well as copy-pasting values around Excel are error-prone processes.
Thus I set out to develop a function that could automatically merge segments into a single data set.
The result of this is [`tread::tunite()`](https://www.gl-eb.me/tread/reference/tunite.html):

1. Each sheet found in a user-supplied `.xlsx` file is read using `tparse()`
2. Then the time-offsets between segments are calculted using their starting times and durations
3. The time for all segments except for the first is adjusted by the total duration and offset of all preceding segments
4. A single data set in tidy format is returned

## Conclusion

I will never know if I have saved the time I have invested into developing tread by not having to manually extract data from Excel sheets (n.b. as of writing I have 579 Tecan-generated `.xlsx` files to show after 3.5 years of PhD).
Nevertheless, the process has been a valuable learning experience and I can only recommend spinning out frequently used functions into packages.
In fact, last year I set up [another package](https://github.com/gl-eb/glebrt) containing a number of functions I commonly use across projects.
I found the second edition of Hadley Wickham and Jennifer Bryan's book [R Packages](https://r-pkgs.org/) to be a fantastic resource in this regard [@wickhamBryanRPackages2e2023].
Creating your first R package might be a bit overwhelming at first, but I took it slow and let it grew organically as my needs evolved.
